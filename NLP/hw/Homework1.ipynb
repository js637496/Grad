{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1: Twenty Small Python/NLTK Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Out: Tuesday, February 11\n",
    "## Due Date: Thursday, February 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introductory programming assignment is composed Python exercises, ranging from introductory to more advanced (OO, inheritance, classes). Python is not a difficult language to learn (as long as you already know a procedural language like Java or C++). However, its syntax is different and there are a handful of very unique features, some of which come in very handy for text processing. You'll discover that you can write powerful Python programs in less lines than would be required in Java.\n",
    "\n",
    "We've already discussed that Python is not a prerequisite for this class, and while we will introduce and practice some aspects of Python in-class, you are expected to google, learn, and practice any other areas of Python that you'll need on your own. Don't be afraid to figure out how to do something!\n",
    "\n",
    "This homework should prepare you for more complicated programming in the weeks ahead. More formally, the objectives of this homework are:\n",
    "* Learning the basics of Python through hands-on programming\n",
    "* Getting comfortable with a Jupyter notebook environment\n",
    "* Testing your code by using provided test cases\n",
    "\n",
    "This is an individual programming assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Resources\n",
    "\n",
    "See the Python resources that I provided on the main coursepage, in week 1 under \"Resources\".\n",
    "I also use google a lot to answer my Python questions -- however, be sure that the \"answers\" that you are looking at are for Python 3.x code. (Version 2.x is still very popular, and thus, often is returned as a higher search result.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "\n",
    "I will primarily be running your notebook against unit tests.\n",
    "\n",
    "_More passing tests = higher grade!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission instructions\n",
    "\n",
    "Submit your `.ipynb` notebook file to the D2L Assignments folder for this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function <code>is_palindrome()</code> that recognizes palindromes (i.e. words that read the same backward or foreward). For example, <code>is_palindrome(\"radar\")</code> should return <samp>True</samp>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(myStr):\n",
    "    myStr = myStr.replace(\" \", \"\").lower()\n",
    "    return myStr == myStr[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_palindrome(\"tattarrattat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function named <code>odd_list</code> that takes a list of numbers and returns a new list that only contains those numbers that are odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_list(numLst):\n",
    "    return [n for n in numLst if n % 2 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_list([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function called <code>is_sorted</code> that takes a list as a parameter and returns <samp>True</samp> if the list is sorted in ascending order and <samp>False</samp> otherwise. You can assume (as a precondition) that the elements of the list can be compared with the relational operators `<`, `>`, etc. For example, `is_sorted([1,2,2])` should return `True` and `is_sorted(['b','a'])` should return `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sorted(myLst):\n",
    "    return myLst == sorted(myLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_sorted(['a','b','a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function `starts_with_vowel` that takes a character (a string of length 1) and returns `True` if it is a vowel, `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starts_with_vowel(myStr):\n",
    "    return myStr.lower().startswith(('a','e','i','o','u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts_with_vowel(\"Ollie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Two words are anagrams if you can rearrange the letters from one to spell the other. Write a function called <code>is_anagram</code> that takes two strings and returns <samp>True</samp> if they are anagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_anagram(str1, str2):\n",
    "    str1 = str1.replace(\" \", \"\").lower()\n",
    "    str2 = str2.replace(\" \", \"\").lower()\n",
    "    return sorted(str1) == sorted(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_anagram(\"school master\", \"the classroom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. A pangram is a sentence that contains all the letters of the English alphabet at least once, for example: <samp>The quick brown fox jumps over the lazy dog</samp>. Write a function <code>is_pangram</code> to check a sentence to see if it is a pangram or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pangram(myStr):\n",
    "    myStr = myStr.lower()\n",
    "    alphabetSet = set([chr(x) for x in range(ord('a'), ord('z') + 1)])\n",
    "    return set(myStr) >= alphabetSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pangram(\"The quick brown fox jumps over the lazy dog abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a function `char_freq()` that takes a string and builds a frequency listing of the characters contained in it. Represent the frequency listing as a Python dictionary that the function returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_freq(myStr):\n",
    "    freq_dict = {}\n",
    "    myStr = myStr.lower()\n",
    "    strSet = set(myStr)\n",
    "    [freq_dict.update({c: 0}) for c in strSet]\n",
    "    [freq_dict.update({c: freq_dict[c] + 1}) for c in myStr]\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 2, 'e': 3, 'g': 1, 'i': 1, 'n': 1, 's': 3, 't': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq(\"testing test test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. In cryptography, a Caesar cipher is a very simple encryption techniques in which each letter in the plain text is replaced by a letter some fixed number of positions down the alphabet. For example, with a shift of 3, `A` would be replaced by `D`, `B` would become `E`, and so on. The method is named after Julius Caesar, who used it to communicate with his generals. <u>ROT-13</u> (\"rotate by 13 places\") is a widely used example of a Caesar cipher where the shift is 13. In Python, the key for ROT-13 may be represented by means of the following dictionary:\n",
    "\n",
    "```python\n",
    "key = {'a':'n', 'b':'o', 'c':'p', 'd':'q', 'e':'r', 'f':'s', 'g':'t', 'h':'u', \n",
    "       'i':'v', 'j':'w', 'k':'x', 'l':'y', 'm':'z', 'n':'a', 'o':'b', 'p':'c', \n",
    "       'q':'d', 'r':'e', 's':'f', 't':'g', 'u':'h', 'v':'i', 'w':'j', 'x':'k',\n",
    "       'y':'l', 'z':'m', 'A':'N', 'B':'O', 'C':'P', 'D':'Q', 'E':'R', 'F':'S', \n",
    "       'G':'T', 'H':'U', 'I':'V', 'J':'W', 'K':'X', 'L':'Y', 'M':'Z', 'N':'A', \n",
    "       'O':'B', 'P':'C', 'Q':'D', 'R':'E', 'S':'F', 'T':'G', 'U':'H', 'V':'I', \n",
    "       'W':'J', 'X':'K', 'Y':'L', 'Z':'M'}\n",
    "```\n",
    "\n",
    "Write two functions: `encode` and `decode`, which take a string and return that string encoded/decoded using ROT-13. For example, the string `To be or not to be, That is the question` would be encoded to `Gb or be abg gb or, Gung vf gur dhrfgvba` using <u>ROT-13</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(myStr):\n",
    "    encodedStr = \"\"\n",
    "    for c in myStr:\n",
    "        index = ord(c)\n",
    "        if (index >= ord('a') and index <= ord('z')) or (index >= ord('A') and index <= ord('Z')):\n",
    "            index = index + 13\n",
    "            if index > ord('z') or (ord(c) < ord('a') and index > ord('Z')): \n",
    "                index = index - 26                \n",
    "        encodedStr += chr(index)\n",
    "    return encodedStr\n",
    "\n",
    "def decode(myStr):\n",
    "    decodedStr = \"\"\n",
    "    for c in myStr:\n",
    "        index = ord(c)\n",
    "        if (index >= ord('a') and index <= ord('z')) or (index >= ord('A') and index <= ord('Z')):\n",
    "            index = index - 13\n",
    "            if index < ord('A') or (ord(c) > ord('Z') and index < ord('a')): \n",
    "                index = index + 26                \n",
    "        decodedStr += chr(index)\n",
    "    return decodedStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be or not to be, That is the question'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(\"Gb or be abg gb or, Gung vf gur dhrfgvba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a function `word_length` that maps a list of words into a list of integers representing the lengths of the correponding words. Use list comprehension to iterate over the list, rather than a \"usual loop\". You must use list comprehension for credit. (Hint: the body of your function should be one line of code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_length(myList):\n",
    "    return [len(w) for w in myList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_length([\"test\",\"hello\",\"ok\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a function named `filter_long_words` that takes a list of words and an integer `n` and returns the list of words, CAPITALIZED, that are longer than `n`. Use list comprehension again, like the last problem, instead of a \"usual loop\". You must use list comprehension for credit. (Hint: the body of your function should be one line of code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_words(myList, n):\n",
    "    return [w.upper() for w in myList if len(w) > n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LONGWORD1', 'LONGWORD2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_long_words([\"hello\",\"longword1\", \"longword2\", \"short\", \"ok\"], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write a function `password_check` that checks the validity of password input by users. The function should accept the password as a string argument, and return True for valid, or False for invalid. The following criteria should be used to check the password:\n",
    "  * it contains at least 1 uppercase letter\n",
    "  * it contains at least 1 number\n",
    "  * it contains at least 1 lowercase letter\n",
    "  * it contains at least 1 of the following symbols: ^@#$%\n",
    "  * it has at least 6 characters\n",
    "  * it has at most 12 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def password_check(pwd):\n",
    "    return bool(re.search(\"^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[^@#$%])[A-Za-z\\d^@#$%]{6,12}$\", pwd))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password_check(\"Password1$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write a function `b_alphabetical` that takes one argument (a list of words) and returns as a list all the words that begin with the letter `b`, in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_alphabetical(myList):\n",
    "    return sorted([c for c in myList if c.startswith('b')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball', 'bat', 'boring', 'boxing']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_alphabetical(['bat','baseball','is','not', 'boxing', 'boring'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write a function `text_select` that finds all words in a specified NLTK text (an `Nltk.Text` object: one of text1, text2, ... text9) that meet the following conditions:\n",
    "  * ending in ize\n",
    "  * containing the letter z\n",
    "  * containing the sequence of letters pt\n",
    "  * are all lowercase, except the first character is a capital letter\n",
    "  \n",
    "Return these words as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def text_select(nltkText):\n",
    "    return [w for w in nltkText if \"pt\" in w and w[0].isupper() and w[1:].islower() and w.endswith(\"ize\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesptize', 'Axptxize']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_select(nltk.Text([\"test\", \"Tesptize\", \"TeSptize\", \"tesptize\", \"Axptxize\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write a function `vocab_size` that takes as an argument an NLTK text, and returns the vocabulary size of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def vocab_size(nltkText):\n",
    "    vocabA = set(w.lower() for w in nltkText if w.isalpha())\n",
    "    return len(vocabA)\n",
    "\n",
    "    #return len([w for w in set(nltkText) if (bool(re.search(\"^[a-zA-Z]*$\", w.replace(\"'s\", \"\"))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.book import text4\n",
    "vocab_size(nltk.book.text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Read in the texts of the State of the Union addresses, using the `state_union` corpus reader. Count occurrences of men, women, and people in each document. Return this information as a dictionary, which the following representation: for each dictionary entry, set the key to be one of the State of the Union addresses, and let the value be a 3-item tuple, which is the number of men, women, and people in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_union():\n",
    "    stateDict = {}\n",
    "    for fileid in nltk.corpus.state_union.fileids():\n",
    "        stateDict.update({fileid: (0,0,0)})\n",
    "        for w in nltk.corpus.state_union.words(fileid):\n",
    "            if (w.lower().startswith(\"men\") or w.lower().startswith(\"women\") or w.lower().startswith(\"people\")) == False:\n",
    "                continue                \n",
    "            tup = stateDict[fileid]\n",
    "            if (w.lower().startswith(\"men\")):\n",
    "                tmp = list(tup)\n",
    "                tmp[0] += 1\n",
    "                tup = tuple(tmp)\n",
    "            if (w.lower().startswith(\"women\")):\n",
    "                tmp = list(tup)\n",
    "                tmp[1] += 1\n",
    "                tup = tuple(tmp)\n",
    "            if (w.lower().startswith(\"people\")):\n",
    "                tmp = list(tup)\n",
    "                tmp[2] += 1\n",
    "                tup = tuple(tmp)\n",
    "            stateDict.update({fileid: tup})   \n",
    "    return stateDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1945-Truman.txt': (2, 2, 10),\n",
       " '1946-Truman.txt': (16, 7, 54),\n",
       " '1947-Truman.txt': (8, 2, 17),\n",
       " '1948-Truman.txt': (5, 1, 24),\n",
       " '1949-Truman.txt': (2, 1, 18),\n",
       " '1950-Truman.txt': (6, 2, 23),\n",
       " '1951-Truman.txt': (9, 2, 15),\n",
       " '1953-Eisenhower.txt': (5, 0, 20),\n",
       " '1954-Eisenhower.txt': (4, 0, 16),\n",
       " '1955-Eisenhower.txt': (9, 0, 31),\n",
       " '1956-Eisenhower.txt': (5, 2, 31),\n",
       " '1957-Eisenhower.txt': (7, 2, 17),\n",
       " '1958-Eisenhower.txt': (3, 1, 21),\n",
       " '1959-Eisenhower.txt': (5, 1, 17),\n",
       " '1960-Eisenhower.txt': (2, 0, 18),\n",
       " '1961-Kennedy.txt': (6, 0, 13),\n",
       " '1962-Kennedy.txt': (7, 2, 10),\n",
       " '1963-Johnson.txt': (1, 0, 3),\n",
       " '1963-Kennedy.txt': (13, 5, 14),\n",
       " '1964-Johnson.txt': (3, 1, 3),\n",
       " '1965-Johnson-1.txt': (10, 0, 16),\n",
       " '1965-Johnson-2.txt': (12, 3, 14),\n",
       " '1966-Johnson.txt': (14, 1, 36),\n",
       " '1967-Johnson.txt': (13, 1, 30),\n",
       " '1968-Johnson.txt': (4, 0, 18),\n",
       " '1969-Johnson.txt': (5, 2, 6),\n",
       " '1970-Nixon.txt': (3, 0, 24),\n",
       " '1971-Nixon.txt': (1, 0, 34),\n",
       " '1972-Nixon.txt': (1, 0, 9),\n",
       " '1973-Nixon.txt': (1, 0, 10),\n",
       " '1974-Nixon.txt': (0, 0, 22),\n",
       " '1975-Ford.txt': (0, 0, 14),\n",
       " '1976-Ford.txt': (3, 1, 18),\n",
       " '1977-Ford.txt': (2, 1, 20),\n",
       " '1978-Carter.txt': (0, 1, 26),\n",
       " '1979-Carter.txt': (0, 1, 16),\n",
       " '1980-Carter.txt': (1, 2, 13),\n",
       " '1981-Reagan.txt': (3, 1, 11),\n",
       " '1982-Reagan.txt': (1, 2, 18),\n",
       " '1983-Reagan.txt': (5, 7, 20),\n",
       " '1984-Reagan.txt': (3, 5, 27),\n",
       " '1985-Reagan.txt': (1, 1, 12),\n",
       " '1986-Reagan.txt': (3, 2, 14),\n",
       " '1987-Reagan.txt': (1, 0, 24),\n",
       " '1988-Reagan.txt': (4, 0, 17),\n",
       " '1989-Bush.txt': (4, 3, 13),\n",
       " '1990-Bush.txt': (3, 2, 10),\n",
       " '1991-Bush-1.txt': (2, 2, 15),\n",
       " '1991-Bush-2.txt': (8, 7, 13),\n",
       " '1992-Bush.txt': (4, 4, 27),\n",
       " '1993-Clinton.txt': (1, 2, 45),\n",
       " '1994-Clinton.txt': (1, 1, 67),\n",
       " '1995-Clinton.txt': (3, 3, 73),\n",
       " '1996-Clinton.txt': (2, 3, 43),\n",
       " '1997-Clinton.txt': (1, 2, 31),\n",
       " '1998-Clinton.txt': (2, 2, 22),\n",
       " '1999-Clinton.txt': (4, 3, 22),\n",
       " '2000-Clinton.txt': (11, 7, 41),\n",
       " '2001-GWBush-1.txt': (5, 3, 15),\n",
       " '2001-GWBush-2.txt': (1, 3, 12),\n",
       " '2002-GWBush.txt': (4, 6, 14),\n",
       " '2003-GWBush.txt': (10, 4, 34),\n",
       " '2004-GWBush.txt': (10, 8, 21),\n",
       " '2005-GWBush.txt': (8, 11, 18),\n",
       " '2006-GWBush.txt': (7, 7, 22)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_union()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Write a function `fifty` that takes an argument, an NLTK text, and returns as a list the 50 most frequently occurring words of the text that are not stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords \n",
    "def fifty(nltkText):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [w for w in nltkText if not w in stop_words] \n",
    "    fdist = FreqDist(filtered_text)\n",
    "    return [list(w)[0] for w in fdist.most_common(50)] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\", '*T*-1', '*U*', '$']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty(nltk.book.text7)[5:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Write a function `novel_10` that takes a NLTK text argument and returns in a list any word that appeared in the last 10% of the text that had not been encountered earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def novel_10(nltkText):\n",
    "    last10Index = math.floor(len(nltkText) * 0.9)\n",
    "    first90Set = set(nltkText[:last10Index-1])\n",
    "    return [w for w in nltkText[last10Index:] if (w in first90Set) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_10(novel_10(nltk.Text(['the','cat','in','the','hat','ate','the','big','hairy','and','gray','rat','hat'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Write a function `sent_info` that takes a sentence expressed as a single string, splits it and counts up the words. Have the function print out each word and the word's frequency, one per line, in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_info(mySent):\n",
    "    fdist = FreqDist(nltk.Text(mySent.split()))\n",
    "    fdcom = sorted(fdist.most_common())\n",
    "    for w in fdcom:\n",
    "        w = list(w)\n",
    "        print(w[0] + \" \" + str(w[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "are 1\n",
      "in 1\n",
      "is 1\n",
      "test 3\n",
      "test, 1\n",
      "testing 1\n",
      "things 1\n",
      "this 2\n",
      "we 1\n"
     ]
    }
   ],
   "source": [
    "sent_info(\"test test this is a test, we are testing things in this test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Write a function `unknown` that takes a URL as its argument, and returns a list of unknown words that occur on that webpage. In order to do this, extract all substrings consisting of lowercase letters (using `re.findall()`) and remove any items from this set that occur in the Words Corpus (`nltk.corpus.words`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from nltk.corpus import words\n",
    "def unknown(url):\n",
    "    req = requests.get(url)\n",
    "    req.encoding = \"utf-8\"\n",
    "    contents = req.text\n",
    "    wordsList = set(words.words())\n",
    "    tmpList = re.findall(r'\\b[a-z]+', contents.lower())\n",
    "    return sorted(set([w for w in tmpList if (w in wordsList) == False]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaahgz',\n",
       " 'aaaalwf',\n",
       " 'aaad',\n",
       " 'aax',\n",
       " 'abbr',\n",
       " 'ac',\n",
       " 'acceptbuttontext',\n",
       " 'accessenablerloader',\n",
       " 'accesskey',\n",
       " 'accountid',\n",
       " 'actionmessage',\n",
       " 'activevariationid',\n",
       " 'adb',\n",
       " 'adbanner',\n",
       " 'adbody',\n",
       " 'adchoices',\n",
       " 'adcomplete',\n",
       " 'adcontainer',\n",
       " 'addeventlistener',\n",
       " 'additionalfields',\n",
       " 'addscript',\n",
       " 'addscriptelement',\n",
       " 'addtopictype',\n",
       " 'adfree',\n",
       " 'adfuel',\n",
       " 'adfuelserviceshost',\n",
       " 'adid',\n",
       " 'adkey',\n",
       " 'admode',\n",
       " 'adnetworkid',\n",
       " 'adnxs',\n",
       " 'adobeenvironment',\n",
       " 'adobeswfpath',\n",
       " 'ads',\n",
       " 'adsconfig',\n",
       " 'adsection',\n",
       " 'adsectionoverridekeys',\n",
       " 'adserverrooturl',\n",
       " 'adsname',\n",
       " 'adsystem',\n",
       " 'adtargets',\n",
       " 'adtimers',\n",
       " 'adtop',\n",
       " 'adv',\n",
       " 'adwaterfall',\n",
       " 'adzones',\n",
       " 'af',\n",
       " 'affects',\n",
       " 'affirming',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'airplanes',\n",
       " 'airports',\n",
       " 'ajax',\n",
       " 'akamaihd',\n",
       " 'alertshub',\n",
       " 'allowautopause',\n",
       " 'allowed',\n",
       " 'allownativefullscreen',\n",
       " 'allowstreamtriggeredadbreaksonios',\n",
       " 'allowtexttrackstyle',\n",
       " 'alsolike',\n",
       " 'altcaptopics',\n",
       " 'alternativeheadline',\n",
       " 'amazon',\n",
       " 'amazona',\n",
       " 'amazonaws',\n",
       " 'amd',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americas',\n",
       " 'amp',\n",
       " 'amphtml',\n",
       " 'amznkey',\n",
       " 'analyticsconfig',\n",
       " 'andrew',\n",
       " 'androied',\n",
       " 'animations',\n",
       " 'animationtime',\n",
       " 'antares',\n",
       " 'antialiased',\n",
       " 'anytime',\n",
       " 'api',\n",
       " 'apibaseurl',\n",
       " 'apiendpoint',\n",
       " 'apikey',\n",
       " 'app',\n",
       " 'appembed',\n",
       " 'appendchild',\n",
       " 'appia',\n",
       " 'appid',\n",
       " 'applicationname',\n",
       " 'applicationnamebyvertical',\n",
       " 'apps',\n",
       " 'appversion',\n",
       " 'apstag',\n",
       " 'arabic',\n",
       " 'archives',\n",
       " 'arguments',\n",
       " 'arial',\n",
       " 'articlebody',\n",
       " 'articlelength',\n",
       " 'articlelist',\n",
       " 'articlesection',\n",
       " 'arts',\n",
       " 'asia',\n",
       " 'aspencontext',\n",
       " 'aspx',\n",
       " 'assetidprefix',\n",
       " 'assetpath',\n",
       " 'async',\n",
       " 'attempts',\n",
       " 'attr',\n",
       " 'au',\n",
       " 'augw',\n",
       " 'australia',\n",
       " 'authtoken',\n",
       " 'authtokenprefix',\n",
       " 'authurl',\n",
       " 'autocomplete',\n",
       " 'autodetect',\n",
       " 'autoplay',\n",
       " 'autoplaymutedenabledpage',\n",
       " 'autoplaymuteenabledpages',\n",
       " 'autoplaysinline',\n",
       " 'autos',\n",
       " 'autoscrollenabled',\n",
       " 'autoscrollinterval',\n",
       " 'autostart',\n",
       " 'autostartdisabledmobilesections',\n",
       " 'autostartwhencmsenabled',\n",
       " 'avatar',\n",
       " 'ayseaszacgqajgaaaaazbm',\n",
       " 'ayseaszacgqajgaaaaazbmqavwmkhaemqahkai',\n",
       " 'ayseaszacgqajgaaaaazbmuavwmkhaemqahkai',\n",
       " 'ayseaszacgqajgceaszacgqajgaaaaazbm',\n",
       " 'ayseaszacgqajgceaszacgqajgaaaaazbmiavwmkhaemqahkai',\n",
       " 'ayseaszacgqajgceaszacgqajgaaaaazbmoavwmkhaemqahkai',\n",
       " 'ayseaszacgqajgceaszacgqajgaaaaazbmwavwmkhaemqahkai',\n",
       " 'azjgdyu',\n",
       " 'backface',\n",
       " 'bannerbreakpoints',\n",
       " 'bannertext',\n",
       " 'barstyles',\n",
       " 'baseline',\n",
       " 'basepath',\n",
       " 'basethumbnailurl',\n",
       " 'baseurl',\n",
       " 'bb',\n",
       " 'bdvaja',\n",
       " 'bea',\n",
       " 'bemtay',\n",
       " 'bestoftv',\n",
       " 'bezier',\n",
       " 'bf',\n",
       " 'bfbfbf',\n",
       " 'bfff',\n",
       " 'bfibwg',\n",
       " 'bfontface',\n",
       " 'bfryeg',\n",
       " 'bg',\n",
       " 'bh',\n",
       " 'bicubic',\n",
       " 'bigpicture',\n",
       " 'bigsky',\n",
       " 'bigskypollduration',\n",
       " 'bj',\n",
       " 'bjekps',\n",
       " 'bk',\n",
       " 'bleacherreport',\n",
       " 'blh',\n",
       " 'bll',\n",
       " 'blockquote',\n",
       " 'blockslate',\n",
       " 'blog',\n",
       " 'blogs',\n",
       " 'blx',\n",
       " 'bodytext',\n",
       " 'boldit',\n",
       " 'boomtrain',\n",
       " 'bootstrapper',\n",
       " 'bounceexchange',\n",
       " 'bqmsqj',\n",
       " 'br',\n",
       " 'branding',\n",
       " 'brandlogo',\n",
       " 'breakingnews',\n",
       " 'breakoutmedia',\n",
       " 'brian',\n",
       " 'bridgeenabled',\n",
       " 'brjje',\n",
       " 'broadcasting',\n",
       " 'browsi',\n",
       " 'brsf',\n",
       " 'bt',\n",
       " 'btn',\n",
       " 'buckets',\n",
       " 'buefaw',\n",
       " 'buffersize',\n",
       " 'bundlehost',\n",
       " 'bundles',\n",
       " 'buttoncolor',\n",
       " 'buttonimage',\n",
       " 'buttonsize',\n",
       " 'buttonstyles',\n",
       " 'buttontext',\n",
       " 'bvtguw',\n",
       " 'bwvecj',\n",
       " 'bwzfxh',\n",
       " 'bxc',\n",
       " 'bxivhb',\n",
       " 'byline',\n",
       " 'bylineimages',\n",
       " 'bylinetext',\n",
       " 'bylinewrap',\n",
       " 'byrulh',\n",
       " 'bzqynm',\n",
       " 'cajtfo',\n",
       " 'calc',\n",
       " 'callout',\n",
       " 'cancelbutton',\n",
       " 'cancelbuttontext',\n",
       " 'canonicalsite',\n",
       " 'canonicalurl',\n",
       " 'capitol',\n",
       " 'caps',\n",
       " 'captopics',\n",
       " 'capvqv',\n",
       " 'cards',\n",
       " 'carousel',\n",
       " 'cars',\n",
       " 'casalemedia',\n",
       " 'categorydropmenu',\n",
       " 'caucuses',\n",
       " 'caused',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'cdn',\n",
       " 'cdnassetpath',\n",
       " 'cdnjs',\n",
       " 'celebrities',\n",
       " 'ceptopics',\n",
       " 'cgmtbu',\n",
       " 'ch',\n",
       " 'changing',\n",
       " 'charset',\n",
       " 'chartbeat',\n",
       " 'checkbox',\n",
       " 'checking',\n",
       " 'checkmark',\n",
       " 'checkorigin',\n",
       " 'children',\n",
       " 'chkpls',\n",
       " 'chromeless',\n",
       " 'chunknames',\n",
       " 'chunks',\n",
       " 'cid',\n",
       " 'cities',\n",
       " 'citysearch',\n",
       " 'classname',\n",
       " 'clearsearch',\n",
       " 'cleartext',\n",
       " 'clickanddragcta',\n",
       " 'clickdragtext',\n",
       " 'clicked',\n",
       " 'clicks',\n",
       " 'clipboardoperationsswf',\n",
       " 'closedcaptions',\n",
       " 'closedcaptionscustommenu',\n",
       " 'closedcaptionson',\n",
       " 'closedcaptionsthreshold',\n",
       " 'cloudflare',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'cnn',\n",
       " 'cnnalt',\n",
       " 'cnnarticletoprail',\n",
       " 'cnnbiz',\n",
       " 'cnnbusiness',\n",
       " 'cnnclock',\n",
       " 'cnncreativemarketing',\n",
       " 'cnndidyoumean',\n",
       " 'cnndotcom',\n",
       " 'cnnent',\n",
       " 'cnnentertainment',\n",
       " 'cnnespanol',\n",
       " 'cnngo',\n",
       " 'cnni',\n",
       " 'cnninternational',\n",
       " 'cnniuk',\n",
       " 'cnnlabs',\n",
       " 'cnnmoney',\n",
       " 'cnnnewsletter',\n",
       " 'cnnnewsource',\n",
       " 'cnnnewwebpushsession',\n",
       " 'cnnnext',\n",
       " 'cnnphotolink',\n",
       " 'cnnpolitics',\n",
       " 'cnnresultslist',\n",
       " 'cnnresultssort',\n",
       " 'cnnsans',\n",
       " 'cnnsearchpagelink',\n",
       " 'cnnsearchpagination',\n",
       " 'cnnsearchsummary',\n",
       " 'cnnsearchterm',\n",
       " 'cnnstore',\n",
       " 'cnnstyle',\n",
       " 'cnntosagreed',\n",
       " 'cnntravel',\n",
       " 'cnnvideoclipboardcopy',\n",
       " 'cnnvr',\n",
       " 'cnnvrimgbg',\n",
       " 'cnnvrimgbgsearch',\n",
       " 'cnnvrimglink',\n",
       " 'cnnvrphotolink',\n",
       " 'cnnwebpushsessioncount',\n",
       " 'cnnxstreamurl',\n",
       " 'co',\n",
       " 'cobrandingtext',\n",
       " 'collapsed',\n",
       " 'collapsedlength',\n",
       " 'collectionlist',\n",
       " 'collinson',\n",
       " 'columnposition',\n",
       " 'columns',\n",
       " 'com',\n",
       " 'comments',\n",
       " 'companionadstates',\n",
       " 'completed',\n",
       " 'components',\n",
       " 'condensedbold',\n",
       " 'condensedlight',\n",
       " 'condensedmedium',\n",
       " 'conditionalremove',\n",
       " 'conditions',\n",
       " 'confirmcookie',\n",
       " 'consentcookie',\n",
       " 'const',\n",
       " 'constantssidprefix',\n",
       " 'containers',\n",
       " 'contentbox',\n",
       " 'contentmode',\n",
       " 'contentmodel',\n",
       " 'contentsource',\n",
       " 'contenttype',\n",
       " 'contexts',\n",
       " 'controls',\n",
       " 'converterservice',\n",
       " 'conviva',\n",
       " 'cookiedomain',\n",
       " 'cookielaw',\n",
       " 'countcookie',\n",
       " 'countcookieexpiry',\n",
       " 'countdowntext',\n",
       " 'countrymap',\n",
       " 'coupons',\n",
       " 'coveragecontainer',\n",
       " 'cp',\n",
       " 'createelement',\n",
       " 'createevent',\n",
       " 'criteo',\n",
       " 'crossorigin',\n",
       " 'css',\n",
       " 'csscolumns',\n",
       " 'csspath',\n",
       " 'cssselector',\n",
       " 'csstransforms',\n",
       " 'cssurl',\n",
       " 'ctatext',\n",
       " 'currencies',\n",
       " 'currencyconverter',\n",
       " 'currentcolor',\n",
       " 'customerkey',\n",
       " 'cutoffpercent',\n",
       " 'cvp',\n",
       " 'cvpadpolicycontext',\n",
       " 'cvpcontext',\n",
       " 'cvplive',\n",
       " 'cvpnetwork',\n",
       " 'cvpprofile',\n",
       " 'cvpstream',\n",
       " 'cvpxhrflash',\n",
       " 'cwfihs',\n",
       " 'cxrxeg',\n",
       " 'cygnus',\n",
       " 'darkprovider',\n",
       " 'darkprovidermessage',\n",
       " 'darkproviderokbutton',\n",
       " 'datacontainer',\n",
       " 'dataset',\n",
       " 'datecreated',\n",
       " 'datemodified',\n",
       " 'datepublished',\n",
       " 'davos',\n",
       " 'db',\n",
       " 'dba',\n",
       " 'dc',\n",
       " 'dd',\n",
       " 'ddc',\n",
       " 'deactive',\n",
       " 'deals',\n",
       " 'debdzp',\n",
       " 'debug',\n",
       " 'decisions',\n",
       " 'deepnav',\n",
       " 'defaultposter',\n",
       " 'defaulttext',\n",
       " 'defaultvalue',\n",
       " 'degrees',\n",
       " 'delays',\n",
       " 'delayvideocarousel',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'demandloadconfig',\n",
       " 'demo',\n",
       " 'desc',\n",
       " 'desktop',\n",
       " 'desktopssid',\n",
       " 'destinations',\n",
       " 'details',\n",
       " 'detected',\n",
       " 'developing',\n",
       " 'dfdfdf',\n",
       " 'dfe',\n",
       " 'dfn',\n",
       " 'dialog',\n",
       " 'digits',\n",
       " 'dir',\n",
       " 'disablehoverthreshold',\n",
       " 'disableinmeganavsublinks',\n",
       " 'disablemeganavlink',\n",
       " 'dismisscookie',\n",
       " 'dismisstime',\n",
       " 'dispatchevent',\n",
       " 'displaylabel',\n",
       " 'djvxas',\n",
       " 'dl',\n",
       " 'dmedianet',\n",
       " 'dnqmqq',\n",
       " 'dns',\n",
       " 'docname',\n",
       " 'doctype',\n",
       " 'documentcloud',\n",
       " 'domid',\n",
       " 'donald',\n",
       " 'dontseebutton',\n",
       " 'dots',\n",
       " 'download',\n",
       " 'dpyarg',\n",
       " 'dr',\n",
       " 'drmgik',\n",
       " 'dropdown',\n",
       " 'dropexpand',\n",
       " 'drtwby',\n",
       " 'dsum',\n",
       " 'dtapvj',\n",
       " 'duffels',\n",
       " 'dusnqn',\n",
       " 'dxfuwl',\n",
       " 'dxrnop',\n",
       " 'dyv',\n",
       " 'eafwdcwa',\n",
       " 'editioncookie',\n",
       " 'editionizedurl',\n",
       " 'editions',\n",
       " 'eds',\n",
       " 'ee',\n",
       " 'eee',\n",
       " 'ehnfs',\n",
       " 'ehoje',\n",
       " 'elections',\n",
       " 'elements',\n",
       " 'email',\n",
       " 'embedded',\n",
       " 'embedlinkpattern',\n",
       " 'embedlinks',\n",
       " 'embeds',\n",
       " 'embedscripts',\n",
       " 'emitted',\n",
       " 'enableadfuelutilities',\n",
       " 'enableadlock',\n",
       " 'enableadsheaderbidding',\n",
       " 'enableaisgdpr',\n",
       " 'enableamazondisplayads',\n",
       " 'enableamazonvideoads',\n",
       " 'enableanalytics',\n",
       " 'enableappia',\n",
       " 'enableaspen',\n",
       " 'enableaspenfortos',\n",
       " 'enableautoplayblock',\n",
       " 'enableautoplaymuted',\n",
       " 'enableautoplaymutedlive',\n",
       " 'enableautoplaymutedvr',\n",
       " 'enablebeemray',\n",
       " 'enablebizmostactivestocks',\n",
       " 'enablebizreact',\n",
       " 'enablebiztickerribbon',\n",
       " 'enablebiztickerribbonfutures',\n",
       " 'enablebouncex',\n",
       " 'enablebreakingnews',\n",
       " 'enablebrowsi',\n",
       " 'enablecep',\n",
       " 'enablechartbeat',\n",
       " 'enablechartbeatmab',\n",
       " 'enablecontainerinjection',\n",
       " 'enablecreativereview',\n",
       " 'enablecriteoads',\n",
       " 'enabled',\n",
       " 'enabledlivestreams',\n",
       " 'enabledpagetypes',\n",
       " 'enableeditionpicker',\n",
       " 'enableensighten',\n",
       " 'enableepicads',\n",
       " 'enablefave',\n",
       " 'enablefollownotify',\n",
       " 'enablefooter',\n",
       " 'enableforallvideos',\n",
       " 'enableforcarousels',\n",
       " 'enableforimages',\n",
       " 'enablefreewheel',\n",
       " 'enablegalleryadrefresh',\n",
       " 'enablegalleryads',\n",
       " 'enablegigyalogin',\n",
       " 'enableinclude',\n",
       " 'enableindexexchange',\n",
       " 'enableinfooter',\n",
       " 'enableinheader',\n",
       " 'enableintegraladscience',\n",
       " 'enableinviewrefresh',\n",
       " 'enablejsmd',\n",
       " 'enablejumbotronautoscroll',\n",
       " 'enablekrux',\n",
       " 'enablelabels',\n",
       " 'enablelazyloadimages',\n",
       " 'enablelivevideogeocheck',\n",
       " 'enablelocalkeypress',\n",
       " 'enablelocalprebid',\n",
       " 'enablelogging',\n",
       " 'enablemalvertisingdetection',\n",
       " 'enablemobilewebfloatingplayer',\n",
       " 'enablemyfinance',\n",
       " 'enableomniture',\n",
       " 'enableoneclicktoplay',\n",
       " 'enableonetapcustomfullscreen',\n",
       " 'enableonetaptoplay',\n",
       " 'enableonetrust',\n",
       " 'enableonfirstzone',\n",
       " 'enableonleaf',\n",
       " 'enableoptimizely',\n",
       " 'enableoutbrain',\n",
       " 'enableoutbrainonetaptoplay',\n",
       " 'enableoutbrainvideokpi',\n",
       " 'enableoutoffocusadrequest',\n",
       " 'enablepiiadfilter',\n",
       " 'enablepinnedduringpause',\n",
       " 'enableprebid',\n",
       " 'enableproximic',\n",
       " 'enablepushalerts',\n",
       " 'enablerefreshtimers',\n",
       " 'enablescalingvideoplayer',\n",
       " 'enablesectionfronts',\n",
       " 'enablesectionlink',\n",
       " 'enablesegmentanalytics',\n",
       " 'enablesharebuttons',\n",
       " 'enablesourcepoint',\n",
       " 'enablespark',\n",
       " 'enabletiming',\n",
       " 'enabletopadscrollover',\n",
       " 'enabletopbanneradabovenav',\n",
       " 'enableuserconsent',\n",
       " 'enableusermessage',\n",
       " 'enableuserregistration',\n",
       " 'enablevideoendslate',\n",
       " 'enablevideoexperienceunification',\n",
       " 'enablevideoexperienceunificationvideopinning',\n",
       " 'enablevideopinning',\n",
       " 'enablevisualrevenuevideo',\n",
       " 'enablewatchlivebutton',\n",
       " 'enableweather',\n",
       " 'enablewhatsappbutton',\n",
       " 'enablezion',\n",
       " 'enablezoneoutbrain',\n",
       " 'encountered',\n",
       " 'endif',\n",
       " 'endslate',\n",
       " 'ensighten',\n",
       " 'entertheatermodeicon',\n",
       " 'entitlementsingletons',\n",
       " 'env',\n",
       " 'eot',\n",
       " 'epicad',\n",
       " 'eq',\n",
       " 'eqsu',\n",
       " 'equiv',\n",
       " 'errorcode',\n",
       " 'errorform',\n",
       " 'errorinfo',\n",
       " 'errormessage',\n",
       " 'errorokbutton',\n",
       " 'errorslate',\n",
       " 'errorurl',\n",
       " 'espa',\n",
       " 'espanol',\n",
       " 'esports',\n",
       " 'esykax',\n",
       " 'et',\n",
       " 'etgcbh',\n",
       " 'etrain',\n",
       " 'eudisabledtext',\n",
       " 'europe',\n",
       " 'events',\n",
       " 'eventtimers',\n",
       " 'evolved',\n",
       " 'examines',\n",
       " 'exceeded',\n",
       " 'excercise',\n",
       " 'excludeedition',\n",
       " 'exe',\n",
       " 'execcommand',\n",
       " 'exittheatermodeicon',\n",
       " 'exlarge',\n",
       " 'exlhie',\n",
       " 'expandable',\n",
       " 'expandbrowsernotifier',\n",
       " 'expandednav',\n",
       " 'expandfull',\n",
       " 'experimentid',\n",
       " 'experiments',\n",
       " 'expirationperiod',\n",
       " 'expired',\n",
       " 'expires',\n",
       " 'explains',\n",
       " 'extracopyrighttext',\n",
       " 'eyj',\n",
       " 'eyjhbgcioijiuzi',\n",
       " 'eyjhbgcioijsuzi',\n",
       " 'eyjhchbjzci',\n",
       " 'eyjzdwiioiiyy',\n",
       " 'ezgxzw',\n",
       " 'facebook',\n",
       " 'facebookmessenger',\n",
       " 'facts',\n",
       " 'fadeindelay',\n",
       " 'fadeout',\n",
       " 'fadeoutdelay',\n",
       " 'fafafa',\n",
       " 'fajfbm',\n",
       " 'fallbackassetid',\n",
       " 'fastforward',\n",
       " 'fastlane',\n",
       " 'fav',\n",
       " 'fave',\n",
       " 'favefreepreview',\n",
       " 'favicon',\n",
       " 'favorites',\n",
       " 'fb',\n",
       " 'fbf',\n",
       " 'fbk',\n",
       " 'fbl',\n",
       " 'featurename',\n",
       " 'features',\n",
       " 'february',\n",
       " 'feeds',\n",
       " 'fefefe',\n",
       " 'ff',\n",
       " 'ffe',\n",
       " 'fff',\n",
       " 'fffak',\n",
       " 'fgjwpp',\n",
       " 'fields',\n",
       " 'fieldset',\n",
       " 'figcaption',\n",
       " 'files',\n",
       " 'films',\n",
       " 'filterholder',\n",
       " 'findbyname',\n",
       " 'firstvisit',\n",
       " 'fivethings',\n",
       " 'fjdhpx',\n",
       " 'fjs',\n",
       " 'fkhcxi',\n",
       " 'flashplayer',\n",
       " 'flashslate',\n",
       " 'flexbox',\n",
       " 'flickercontrol',\n",
       " 'flyout',\n",
       " 'fmvw',\n",
       " 'fnt',\n",
       " 'focuskeyname',\n",
       " 'focusring',\n",
       " 'fontface',\n",
       " 'fonts',\n",
       " 'foodanddrink',\n",
       " 'footerstart',\n",
       " 'footerstyles',\n",
       " 'forms',\n",
       " 'fp',\n",
       " 'fqfamc',\n",
       " 'frameborder',\n",
       " 'friday',\n",
       " 'fueled',\n",
       " 'fullscreen',\n",
       " 'fullscreenmaxbitrate',\n",
       " 'fullstandardwidth',\n",
       " 'fullwidth',\n",
       " 'fwmrm',\n",
       " 'fwnetworkid',\n",
       " 'fwprofile',\n",
       " 'fxrqgn',\n",
       " 'fyifot',\n",
       " 'fyre',\n",
       " 'gadgets',\n",
       " 'galleryadclicks',\n",
       " 'gallerycaption',\n",
       " 'games',\n",
       " 'gatewayurl',\n",
       " 'gb',\n",
       " 'gcodmo',\n",
       " 'gcrmut',\n",
       " 'geocheckenabled',\n",
       " 'geochecktargets',\n",
       " 'georgia',\n",
       " 'geoslate',\n",
       " 'germany',\n",
       " 'getadkey',\n",
       " 'getcaptopics',\n",
       " 'getceptopics',\n",
       " 'getconfig',\n",
       " 'getelementbyid',\n",
       " 'getelementsbytagname',\n",
       " 'getforecast',\n",
       " 'getproximicdata',\n",
       " 'getrefdom',\n",
       " 'gets',\n",
       " 'getspecbranding',\n",
       " 'gigya',\n",
       " 'globaladtimer',\n",
       " 'globetrotting',\n",
       " 'gm',\n",
       " 'gofreepreview',\n",
       " 'gofreepreviewconfig',\n",
       " 'goodstuff',\n",
       " 'google',\n",
       " 'googleadservices',\n",
       " 'googleplus',\n",
       " 'googlesyndication',\n",
       " 'googletagservices',\n",
       " 'gosmartlink',\n",
       " 'gouxwa',\n",
       " 'gov',\n",
       " 'gpt',\n",
       " 'gqjmru',\n",
       " 'grabcursortimeout',\n",
       " 'graphql',\n",
       " 'graphqluri',\n",
       " 'grayscale',\n",
       " 'greatbigstorycnnnewsletter',\n",
       " 'grlnzl',\n",
       " 'grumman',\n",
       " 'gscewi',\n",
       " 'gt',\n",
       " 'guides',\n",
       " 'gupta',\n",
       " 'gwkclp',\n",
       " 'gyetwy',\n",
       " 'gzmcbi',\n",
       " 'gzvnrw',\n",
       " 'has',\n",
       " 'hashtag',\n",
       " 'hasvideo',\n",
       " 'hdnea',\n",
       " 'headend',\n",
       " 'headerbar',\n",
       " 'headerimage',\n",
       " 'headerless',\n",
       " 'headermedia',\n",
       " 'headerstyles',\n",
       " 'headertext',\n",
       " 'headlines',\n",
       " 'heads',\n",
       " 'heavyit',\n",
       " 'helplink',\n",
       " 'helvetica',\n",
       " 'heroes',\n",
       " 'hfuihj',\n",
       " 'hfujui',\n",
       " 'hgroup',\n",
       " 'highlights',\n",
       " 'hk',\n",
       " 'hln',\n",
       " 'hnyoqv',\n",
       " 'homepage',\n",
       " 'homes',\n",
       " 'horseracing',\n",
       " 'hotels',\n",
       " 'hotlinks',\n",
       " 'hotstocks',\n",
       " 'hours',\n",
       " 'hpt',\n",
       " 'hr',\n",
       " 'href',\n",
       " 'hreflang',\n",
       " 'hrjndn',\n",
       " 'hsla',\n",
       " 'ht',\n",
       " 'htdaso',\n",
       " 'html',\n",
       " 'htmladloadtimeout',\n",
       " 'htodjs',\n",
       " 'htpnat',\n",
       " 'http',\n",
       " 'https',\n",
       " 'humans',\n",
       " 'hyvhvp',\n",
       " 'iab',\n",
       " 'iabt',\n",
       " 'ib',\n",
       " 'ico',\n",
       " 'icons',\n",
       " 'ideas',\n",
       " 'ids',\n",
       " 'idx',\n",
       " 'iefix',\n",
       " 'iemobile',\n",
       " 'ieunsupported',\n",
       " 'ifakcx',\n",
       " 'iframe',\n",
       " 'iframeclient',\n",
       " 'iframeconfig',\n",
       " 'iframehost',\n",
       " 'iframehtml',\n",
       " 'iframeresize',\n",
       " 'iframeresizer',\n",
       " 'iitfdo',\n",
       " 'ikqpmq',\n",
       " 'iksuii',\n",
       " 'imagebreakpoints',\n",
       " 'imagebuttonxoffset',\n",
       " 'imagebuttonyoffset',\n",
       " 'images',\n",
       " 'imageurl',\n",
       " 'img',\n",
       " 'inbox',\n",
       " 'inc',\n",
       " 'indexof',\n",
       " 'indexww',\n",
       " 'india',\n",
       " 'info',\n",
       " 'infocus',\n",
       " 'infographic',\n",
       " 'init',\n",
       " 'initevent',\n",
       " 'initialrendition',\n",
       " 'initials',\n",
       " 'injectcss',\n",
       " 'injectorjs',\n",
       " 'inline',\n",
       " 'inlinesharebar',\n",
       " 'innercontainer',\n",
       " 'innerheight',\n",
       " 'inpage',\n",
       " 'insertbefore',\n",
       " 'insights',\n",
       " 'instagram',\n",
       " 'instagramjs',\n",
       " 'instanceof',\n",
       " 'instructions',\n",
       " 'instructionsurl',\n",
       " 'internet',\n",
       " 'interviews',\n",
       " 'intl',\n",
       " 'inuserconsentstate',\n",
       " 'investigates',\n",
       " 'investigations',\n",
       " 'investing',\n",
       " 'invoked',\n",
       " 'ios',\n",
       " 'ipad',\n",
       " 'iphone',\n",
       " 'ireport',\n",
       " 'isarray',\n",
       " 'isarticlevideocollection',\n",
       " 'isdefault',\n",
       " 'isembeddable',\n",
       " 'islink',\n",
       " 'isoversizelimit',\n",
       " 'ispartof',\n",
       " 'iss',\n",
       " 'isshorturl',\n",
       " 'isstack',\n",
       " 'issubsection',\n",
       " 'issues',\n",
       " 'isunderscore',\n",
       " 'isusable',\n",
       " 'iswebview',\n",
       " 'italic',\n",
       " 'itemprop',\n",
       " 'items',\n",
       " 'itemscope',\n",
       " 'itemtype',\n",
       " 'iwskbi',\n",
       " 'ja',\n",
       " 'jackets',\n",
       " 'jafsvs',\n",
       " 'jan',\n",
       " 'javascript',\n",
       " 'jessica',\n",
       " 'jjwzwe',\n",
       " 'jkfeox',\n",
       " 'jlztwo',\n",
       " 'jobs',\n",
       " 'jp',\n",
       " 'jpg',\n",
       " 'jplayer',\n",
       " 'jpsuperheaderwrapper',\n",
       " 'jquery',\n",
       " 'jr',\n",
       " 'js',\n",
       " 'jsmd',\n",
       " 'jsmdnewapi',\n",
       " 'jsmdtveapi',\n",
       " 'jsmducstates',\n",
       " 'json',\n",
       " 'jsonp',\n",
       " 'jsp',\n",
       " 'jstodn',\n",
       " 'jsx',\n",
       " 'jtzltm',\n",
       " 'judizn',\n",
       " 'jumbotron',\n",
       " 'jumbotronconfig',\n",
       " 'jysrsx',\n",
       " 'kaaaaaaaaaaaaaaaaaaaaaaaeaaaaaaaaaaaaaaaaaaaabaaaaaaaaaaaaaaaaaabaaaaaalaaaacqaaaaaaakzwr',\n",
       " 'kallingal',\n",
       " 'kanqnf',\n",
       " 'kaxydh',\n",
       " 'kbd',\n",
       " 'kchwka',\n",
       " 'kdwvgm',\n",
       " 'keyframes',\n",
       " 'keynewsletter',\n",
       " 'keywords',\n",
       " 'khhqsk',\n",
       " 'khtml',\n",
       " 'kjetjg',\n",
       " 'kkgidq',\n",
       " 'kkv',\n",
       " 'klcdhr',\n",
       " 'kmmbbh',\n",
       " 'knpsyj',\n",
       " 'kr',\n",
       " 'krxd',\n",
       " 'ks',\n",
       " 'ksljys',\n",
       " 'kvgdhb',\n",
       " 'kvhmtw',\n",
       " 'kxpksg',\n",
       " 'laavcq',\n",
       " 'labelonly',\n",
       " 'labeloverride',\n",
       " 'lang',\n",
       " 'lastmod',\n",
       " 'lastupdateddate',\n",
       " 'launched',\n",
       " 'launches',\n",
       " 'launching',\n",
       " 'lawrence',\n",
       " 'layoutstates',\n",
       " 'layouttype',\n",
       " 'lazyload',\n",
       " 'lb',\n",
       " 'ld',\n",
       " 'ldlybg',\n",
       " 'leftarrow',\n",
       " 'legaldocs',\n",
       " 'lendingtree',\n",
       " 'lf',\n",
       " 'lhgfug',\n",
       " 'lib',\n",
       " 'libs',\n",
       " 'lifestyle',\n",
       " 'liftoff',\n",
       " 'lightbox',\n",
       " 'lightboxoverlay',\n",
       " 'lightit',\n",
       " 'liked',\n",
       " 'linkedin',\n",
       " 'linksstyles',\n",
       " 'listexpandable',\n",
       " 'lists',\n",
       " 'liveblog',\n",
       " 'livefyre',\n",
       " 'liveoffline',\n",
       " 'livestream',\n",
       " 'll',\n",
       " 'lmrhr',\n",
       " 'loaderbaseurl',\n",
       " 'loaderbaseurlfullpath',\n",
       " 'loaderbaseurllocal',\n",
       " 'loadfeature',\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown(\"https://www.cnn.com/2020/02/15/us/nasa-launch-experiments-supplies-space-station-trnd/index.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define $\\mu_w$ to be the average number of letters per word, and $\\mu_s$ to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: $$4.71 \\mu w + 0.5 \\mu s - 21.43$$. Write a function `readability` that computes the ARI score for various sections of the Brown Corpus. The function should take as an arugment a section of the Brown Corpus represented by a letter (e.g. Section F is \"popular lore\" and Section J is \"learned\"). Make use of the fact that `nltk.corpus.brown.words()` produces a sequence of words, while `nltk.corpus.brown.sents()` produces a sequence of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability(section):\n",
    "    letters = 0\n",
    "    words = 0\n",
    "    sents = 0\n",
    "    for fileid in nltk.corpus.brown.fileids():\n",
    "        if fileid.startswith(\"c\" + section):\n",
    "            words += len(nltk.corpus.brown.words(fileid))\n",
    "            smash = ''.join(nltk.corpus.brown.words(fileid))\n",
    "            letters += len(smash)\n",
    "            sents += len(nltk.corpus.brown.sents(fileid))\n",
    "    uw = letters / words\n",
    "    us = words / sents\n",
    "    ari = (4.71 * uw ) + ( 0.5 * us ) - 21.43\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.254756197101155"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readability(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Execute the following <u>two cells</u> which specifies some unit tests for the above problems:\n",
    "* The first cell specifies the tests.\n",
    "* The second cell runs the tests.\n",
    "\n",
    "I will test your code using these, as well as other held-out tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "\n",
    "    def test_is_palindrome(self):\n",
    "        self.assertTrue(is_palindrome(\"radar\"))\n",
    "        self.assertFalse(is_palindrome(\"radars\"))\n",
    "\n",
    "    def test_odd_list(self):\n",
    "        self.assertEqual(odd_list([1,2,3,4,5]), [1,3,5])\n",
    "\n",
    "    def test_is_sorted(self):\n",
    "        self.assertTrue(is_sorted([1,2,2]))\n",
    "        self.assertFalse(is_sorted(['b','a']))\n",
    "        \n",
    "    def test_starts_with_vowel(self):\n",
    "        self.assertTrue(starts_with_vowel(\"a\"))\n",
    "        self.assertTrue(starts_with_vowel(\"U\"))        \n",
    "\n",
    "    def test_is_anagram(self):\n",
    "        self.assertTrue(is_anagram(\"school master\", \"the classroom\"))\n",
    "        self.assertFalse(is_anagram(\"school\", \"classroom\"))\n",
    "\n",
    "    def test_is_pangram(self):\n",
    "        self.assertTrue(is_pangram(\"the quick brown fox jumps over the lazy dog\"))\n",
    "        self.assertFalse(is_pangram(\"the quick brown fox jumps over the lazy fox\"))\n",
    "\n",
    "    def test_char_freq(self):\n",
    "        self.assertEqual(char_freq('to be or not to be'),\n",
    "                         {'t':3, 'o':4, ' ':5, 'b':2, 'e':2, 'r':1, 'n':1})\n",
    "\n",
    "    def test_encode(self):\n",
    "        self.assertEqual(encode(\"To be or not to be, That is the question\"), \"Gb or be abg gb or, Gung vf gur dhrfgvba\")\n",
    "\n",
    "    def test_decode(self):\n",
    "        self.assertEqual(decode(\"Gb or be abg gb or, Gung vf gur dhrfgvba\"), \"To be or not to be, That is the question\")\n",
    "\n",
    "    def test_word_length(self):\n",
    "        self.assertEqual(word_length([\"the\", \"quick\", \"brown\", \"fox\"]), [3, 5, 5, 3])\n",
    "\n",
    "    def test_filter_long_words(self):\n",
    "        self.assertEqual(filter_long_words([\"the\", \"quick\", \"brown\", \"fox\"], 4), [\"QUICK\", \"BROWN\"])\n",
    "        \n",
    "    def test_password_check(self):\n",
    "        self.assertFalse(password_check('password'))          \n",
    "        self.assertTrue(password_check('pAs$w0rd'))\n",
    "\n",
    "    def test_b_alphabetical(self):\n",
    "        self.assertEqual(b_alphabetical(['baseball','is','not','boring']), ['baseball','boring'])\n",
    "\n",
    "    def test_text_select(self):\n",
    "        self.assertEqual(text_select(nltk.Text(['the','cat','Axptxize','in'])), ['Axptxize'])\n",
    "        self.assertEqual(text_select(nltk.Text(['the','cat','in'])), [])\n",
    "        self.assertEqual(text_select(nltk.Text(['the','Pdgspsdptize','Axptxize','in'])), \n",
    "            ['Pdgspsdptize','Axptxize'])\n",
    "\n",
    "    def test_vocab_size(self):\n",
    "        self.assertEqual(vocab_size(nltk.book.text4), 9754)  \n",
    "        self.assertEqual(vocab_size(nltk.Text(['the','cat','in','the','hat'])), 4)\n",
    "    \n",
    "    def test_state_union(self):\n",
    "        dict = state_union()\n",
    "        self.assertEqual(dict['2006-GWBush.txt'], (7,7,22))\n",
    "\n",
    "    def test_fifty(self):\n",
    "        self.assertEqual(fifty(nltk.book.text7)[:5], [',', '.', '*-1', '0', '*'])\n",
    "        self.assertEqual(fifty(nltk.book.text7)[5:9], [\"'s\", '*T*-1', '*U*', '$'])\n",
    "        self.assertTrue('million' in fifty(nltk.book.text7))\n",
    "        self.assertTrue('said' in fifty(nltk.book.text7))\n",
    "        self.assertFalse('he' in fifty(nltk.book.text7))\n",
    "        self.assertFalse('deposit' in fifty(nltk.book.text7))\n",
    "\n",
    "\n",
    "    def test_novel_10(self):\n",
    "        self.assertEqual(novel_10(nltk.Text(['the','cat','in','the','hat','ate','the','big','hairy','and','gray','rat','hat'])), ['rat'])\n",
    "\n",
    "    # TODO -- fix this test\n",
    "    def test_sent_info(self):\n",
    "        self.assertEqual(sent_info('the cat in the hat'),\n",
    "            \"\"\"cat 1\n",
    "hat 1\n",
    "in 1\n",
    "the 2\"\"\")\n",
    "\n",
    "    \n",
    "    def test_unknown(self):\n",
    "        #unknownlist = unknown('http://www.cs.wcupa.edu/rburns/NLP')\n",
    "        unknownlist = unknown('http://www.google.com')\n",
    "        self.assertFalse('event' in unknownlist)\n",
    "        self.assertFalse('credit' in unknownlist)\n",
    "        self.assertTrue('google' in unknownlist)\n",
    "\n",
    "    def test_readability(self):\n",
    "        self.assertAlmostEqual(readability('f'), 10.254756197101155, places=2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_b_alphabetical (__main__.TestMethods) ... ok\n",
      "test_char_freq (__main__.TestMethods) ... ok\n",
      "test_decode (__main__.TestMethods) ... ok\n",
      "test_encode (__main__.TestMethods) ... ok\n",
      "test_fifty (__main__.TestMethods) ... ok\n",
      "test_filter_long_words (__main__.TestMethods) ... ok\n",
      "test_is_anagram (__main__.TestMethods) ... ok\n",
      "test_is_palindrome (__main__.TestMethods) ... ok\n",
      "test_is_pangram (__main__.TestMethods) ... ok\n",
      "test_is_sorted (__main__.TestMethods) ... ok\n",
      "test_novel_10 (__main__.TestMethods) ... ok\n",
      "test_odd_list (__main__.TestMethods) ... ok\n",
      "test_password_check (__main__.TestMethods) ... ok\n",
      "test_readability (__main__.TestMethods) ... ok\n",
      "test_sent_info (__main__.TestMethods) ... FAIL\n",
      "test_starts_with_vowel (__main__.TestMethods) ... ok\n",
      "test_state_union (__main__.TestMethods) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 1\n",
      "hat 1\n",
      "in 1\n",
      "the 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_text_select (__main__.TestMethods) ... ok\n",
      "test_unknown (__main__.TestMethods) ... ok\n",
      "test_vocab_size (__main__.TestMethods) ... FAIL\n",
      "test_word_length (__main__.TestMethods) ... ok\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_sent_info (__main__.TestMethods)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-64-d29374e0ab17>\", line 83, in test_sent_info\n",
      "    the 2\"\"\")\n",
      "AssertionError: None != 'cat 1\\nhat 1\\nin 1\\nthe 2'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_vocab_size (__main__.TestMethods)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-64-d29374e0ab17>\", line 58, in test_vocab_size\n",
      "    self.assertEqual(vocab_size(nltk.book.text4), 9754)\n",
      "AssertionError: 9110 != 9754\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 3.799s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fa13c938898>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
